import sqlite3
import os
import shutil
import stat
import time
import logging
from collections import defaultdict

# ==========================================
# è¨­å®š & ãƒ‘ã‚¹å®šç¾©
# ==========================================
DB_PATH = "seo_content.db"
SITE_DIR = "my_site"
DOCS_DIR = os.path.join(SITE_DIR, "docs")
TOOLS_DIR = os.path.join(DOCS_DIR, "tools")

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# ==========================================
# ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•°
# ==========================================
def on_rm_error(func, path, exc_info):
    """
    Windowsã§å‰Šé™¤ã«å¤±æ•—ã—ãŸå ´åˆï¼ˆèª­ã¿å–ã‚Šå°‚ç”¨ãªã©ï¼‰ã€
    å±æ€§ã‚’å¤‰æ›´ã—ã¦å†è©¦è¡Œã™ã‚‹ãŸã‚ã®ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒ©
    """
    try:
        os.chmod(path, stat.S_IWRITE)
        func(path)
    except Exception as e:
        logger.warning(f"Could not remove {path}: {e}")

def safe_filename(url: str) -> str:
    """URLã‹ã‚‰å®‰å…¨ãªãƒ•ã‚¡ã‚¤ãƒ«åã‚’ç”Ÿæˆã™ã‚‹"""
    # æœ«å°¾ã®ã‚¹ãƒ©ãƒƒã‚·ãƒ¥ã‚’é™¤å»ã—ã¦æœ€å¾Œã®ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’å–å¾—
    name = url.strip("/").split("/")[-1]
    
    # ã‚‚ã—åå‰ãŒå–å¾—ã§ããªã„ã€ã‚ã‚‹ã„ã¯çŸ­ã™ãã‚‹å ´åˆã¯ãƒãƒƒã‚·ãƒ¥å€¤ã‚’ä½¿ã†
    if not name or len(name) < 2:
        name = f"article_{abs(hash(url))}"
    
    # æ‹¡å¼µå­ .html ãªã©ãŒå«ã¾ã‚Œã¦ã„ãŸã‚‰é™¤å»ã—ã¦ .md ã«ã™ã‚‹
    if "." in name:
        name = name.split(".")[0]
        
    return f"{name}.md"

def init_directories():
    """è¨˜äº‹æ ¼ç´ç”¨ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª(tools)ã®åˆæœŸåŒ–"""
    if os.path.exists(TOOLS_DIR):
        logger.info(f"Cleaning up old directory: {TOOLS_DIR}")
        try:
            shutil.rmtree(TOOLS_DIR, onerror=on_rm_error)
        except Exception as e:
            logger.error(f"Failed to clean directory: {e}")
            time.sleep(1)
            try:
                shutil.rmtree(TOOLS_DIR, ignore_errors=True)
            except:
                pass

    os.makedirs(TOOLS_DIR, exist_ok=True)

# ==========================================
# ãƒ¡ã‚¤ãƒ³å‡¦ç†
# ==========================================
def export_articles():
    """DBã‹ã‚‰è¨˜äº‹ã‚’èª­ã¿å‡ºã—ã€ã‚«ãƒ†ã‚´ãƒªã”ã¨ã«æ•´ç†ã—ã¦æ›¸ãå‡ºã™"""
    init_directories()

    conn = sqlite3.connect(DB_PATH)
    conn.row_factory = sqlite3.Row
    cursor = conn.cursor()

    # ã‚«ãƒ†ã‚´ãƒªã”ã¨ã®è¨˜äº‹ãƒªã‚¹ãƒˆã‚’ä¿æŒã™ã‚‹è¾æ›¸
    # ã‚­ãƒ¼: ã‚«ãƒ†ã‚´ãƒªå, å€¤: è¨˜äº‹æƒ…å ±ã®ãƒªã‚¹ãƒˆ
    categorized_articles = defaultdict(list)

    try:
        # 1. è¨˜äº‹ãƒ‡ãƒ¼ã‚¿ã®å–å¾— (categoryã‚«ãƒ©ãƒ ã‚‚å«ã‚ã‚‹)
        try:
            query = "SELECT url, title, generated_body, category FROM products WHERE generated_body IS NOT NULL AND generated_body != ''"
            cursor.execute(query)
        except sqlite3.OperationalError:
            # ä¸‡ãŒä¸€ category ã‚«ãƒ©ãƒ ãŒãªã„å ´åˆã¸ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            logger.warning("'category' column missing. Fetching without category.")
            query = "SELECT url, title, generated_body, 'Uncategorized' as category FROM products WHERE generated_body IS NOT NULL AND generated_body != ''"
            cursor.execute(query)

        rows = cursor.fetchall()

        if not rows:
            logger.warning("No articles found in database to export.")
            return

        logger.info(f"Found {len(rows)} articles. Exporting...")

        # 2. å€‹åˆ¥è¨˜äº‹ãƒ•ã‚¡ã‚¤ãƒ«(.md)ã®ç”Ÿæˆ
        for row in rows:
            url = row['url']
            title = row['title']
            body = row['generated_body']
            # DBã«ã‚«ãƒ†ã‚´ãƒªãŒãªã„å ´åˆ(None)ã¯ 'Uncategorized' ã¨ã™ã‚‹
            category = row['category'] if row['category'] else 'Uncategorized'

            # ---------------------------------------------------------
            # ã€è¿½åŠ å‡¦ç†ã€‘å‚ç…§å…ƒãƒªãƒ³ã‚¯ãƒœã‚¿ãƒ³ã‚’è¨˜äº‹æœ«å°¾ã«è¿½åŠ 
            # ---------------------------------------------------------
            if url:
                # MkDocs Material ãƒ†ãƒ¼ãƒç”¨ã‚«ãƒ¼ãƒ‰å‹ãƒªãƒ³ã‚¯
                # generated_body ã®å¾Œã«åŒºåˆ‡ã‚Šç·šã¨ãƒœã‚¿ãƒ³ã‚’è¿½åŠ 
                link_block = f"""

---

<div class="grid cards" markdown>
-   [:material-link-variant: å…ƒã®ãƒšãƒ¼ã‚¸ã§è©³ç´°ã‚’è¦‹ã‚‹]({url})
</div>
"""
                body += link_block
            # ---------------------------------------------------------

            filename = safe_filename(url)
            filepath = os.path.join(TOOLS_DIR, filename)

            # è¨˜äº‹æ›¸ãå‡ºã—
            try:
                with open(filepath, "w", encoding="utf-8") as f:
                    f.write(body)
                
                # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆç”¨ã«ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜
                categorized_articles[category].append({
                    "title": title,
                    "path": f"tools/{filename}" # index.md ã‹ã‚‰è¦‹ãŸç›¸å¯¾ãƒ‘ã‚¹
                })
                
                logger.info(f"Exported [{category}]: {filename}")
            except Exception as e:
                logger.error(f"Failed to write {filename}: {e}")

        # 3. ãƒˆãƒƒãƒ—ãƒšãƒ¼ã‚¸ (index.md) ã®ç”Ÿæˆ
        create_index_page(categorized_articles)

    except Exception as e:
        logger.error(f"Database error: {e}")
    finally:
        conn.close()
        logger.info("Export process completed.")

def create_index_page(categorized_articles):
    """ã‚«ãƒ†ã‚´ãƒªåˆ†ã‘ã•ã‚ŒãŸè¨˜äº‹ãƒªã‚¹ãƒˆã‹ã‚‰ index.md ã‚’ç”Ÿæˆã™ã‚‹"""
    index_path = os.path.join(DOCS_DIR, "index.md")
    
    logger.info("Generating index.md...")

    with open(index_path, "w", encoding="utf-8") as f:
        # ã‚µã‚¤ãƒˆãƒ˜ãƒƒãƒ€ãƒ¼
        f.write("# AI Tech Review\n\n")
        f.write("æœ€æ–°ã®AIãƒ„ãƒ¼ãƒ«ã€æŠ€è¡“ãƒˆãƒ¬ãƒ³ãƒ‰ã€ã‚¬ã‚¸ã‚§ãƒƒãƒˆæƒ…å ±ã‚’ç¶²ç¾…ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã§ã™ã€‚\n\n")

        # ã‚»ã‚¯ã‚·ãƒ§ãƒ³1: ã‚¬ã‚¸ã‚§ãƒƒãƒˆ (Gadget)
        if "Gadget" in categorized_articles and categorized_articles["Gadget"]:
            f.write("## ğŸ† æœ€æ–°ã‚¬ã‚¸ã‚§ãƒƒãƒˆãƒ©ãƒ³ã‚­ãƒ³ã‚° (Gadget)\n\n")
            f.write("ä¾¡æ ¼.comã‚„æ¥½å¤©ã®ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‹ã‚‰å³é¸ã—ãŸæ³¨ç›®ã‚¬ã‚¸ã‚§ãƒƒãƒˆã€‚\n\n")
            for article in categorized_articles["Gadget"]:
                f.write(f"- [{article['title']}]({article['path']})\n")
            f.write("\n")

        # ã‚»ã‚¯ã‚·ãƒ§ãƒ³2: æŠ€è¡“ãƒ‹ãƒ¥ãƒ¼ã‚¹ (Tech News)
        if "Tech News" in categorized_articles and categorized_articles["Tech News"]:
            f.write("## ğŸ“° æŠ€è¡“ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ‹ãƒ¥ãƒ¼ã‚¹ (Tech News)\n\n")
            f.write("Zennãªã©ã®æŠ€è¡“ãƒ¡ãƒ‡ã‚£ã‚¢ã§è©±é¡Œã®ãƒˆãƒ”ãƒƒã‚¯ã‚’è§£èª¬ã€‚\n\n")
            for article in categorized_articles["Tech News"]:
                f.write(f"- [{article['title']}]({article['path']})\n")
            f.write("\n")

        # ã‚»ã‚¯ã‚·ãƒ§ãƒ³3: AIãƒ„ãƒ¼ãƒ« (AI Tool)
        if "AI Tool" in categorized_articles and categorized_articles["AI Tool"]:
            f.write("## ğŸ¤– AIãƒ„ãƒ¼ãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ (AI Tool)\n\n")
            f.write("æ¥­å‹™åŠ¹ç‡åŒ–ã«å½¹ç«‹ã¤æœ€æ–°AIãƒ„ãƒ¼ãƒ«ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ã€‚\n\n")
            for article in categorized_articles["AI Tool"]:
                f.write(f"- [{article['title']}]({article['path']})\n")
            f.write("\n")
            
        # ãã®ä»– (Uncategorized)
        if "Uncategorized" in categorized_articles and categorized_articles["Uncategorized"]:
            f.write("## ğŸ“ ãã®ä»–\n\n")
            for article in categorized_articles["Uncategorized"]:
                f.write(f"- [{article['title']}]({article['path']})\n")
            f.write("\n")

    logger.info("index.md updated successfully.")

if __name__ == "__main__":
    export_articles()